# Hanhan_Data_Science_Resources
helpful resources for (big) data science


* Data Preprocessing

 * Data Exploration: http://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/
 * Data Exploration PDF: https://github.com/hanhanwu/Hanhan_Data_Science_Resources/blob/master/data%20exploration.pdf
 * Faster Data Manipulation with 7 R Packages: http://www.analyticsvidhya.com/blog/2015/12/faster-data-manipulation-7-packages/
 

*******************************************************

* R

 * R Basics: http://www.analyticsvidhya.com/blog/2016/02/complete-tutorial-learn-data-science-scratch/
 * Code for R Basics: https://github.com/hanhanwu/Hanhan_Data_Science_Practice/blob/master/R_Basics.R
 * Data Set for R Basics: http://datahack.analyticsvidhya.com/contest/practice-problem-bigmart-sales-prediction
 * Interesting R Librarise Graph: http://www.analyticsvidhya.com/blog/2015/08/list-r-packages-data-analysis/
 * R Visualization Basics: http://www.analyticsvidhya.com/blog/2015/07/guide-data-visualization-r/
 * Data Visualization Cheatsheet (ggplot2): https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf
 

********************************************************

* Terminology Wiki

 * Multicollinearity: https://en.wikipedia.org/wiki/Multicollinearity
 * Autocorrelation: https://en.wikipedia.org/wiki/Autocorrelation#Regression_analysis
 * Heteroscedasticity: https://en.wikipedia.org/wiki/Heteroscedasticity


********************************************************

* Data Analysis Tricks and Tips

 * Ensemble modeling offers one of the most convincing way to build highly accurate predictive models. The availability of bagging and boosting algorithms further embellishes this method to produce awesome accuracy level.
 * Basic Ensemble Modeling: http://www.analyticsvidhya.com/blog/2015/08/introduction-ensemble-learning/
 * Ensemble Modeling: http://www.analyticsvidhya.com/blog/2015/09/questions-ensemble-modeling/
 * We can combine multiple models of same ML algorithms, but combining multiple predictions generated by different algorithms would normally give you better predictions. It is due to the diversification or independent nature as compared to each other.
 * AdaBoost and Gradient Boost: http://www.analyticsvidhya.com/blog/2015/05/boosting-algorithms-simplified/
 * Boosting may lead to overfittig if the sample data is too small.
 * All the Ensemble methods (Bagging, Boosting, Stacking) may lead to overfitting.
 * Finding Optimal Weights of Ensemble Learner using Neural Network: http://www.analyticsvidhya.com/blog/2015/08/optimal-weights-ensemble-learner-neural-network/
 * Bagging Sample in R: http://www.analyticsvidhya.com/blog/2015/09/selection-techniques-ensemble-modelling/
